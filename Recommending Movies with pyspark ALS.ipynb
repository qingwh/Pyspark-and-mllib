{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ratings: 100836\n",
      "Sample of ratings:\n",
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|      1|   4.0|964982703|\n",
      "|     1|      3|   4.0|964981247|\n",
      "|     1|      6|   4.0|964982224|\n",
      "|     1|     47|   5.0|964983815|\n",
      "|     1|     50|   5.0|964982931|\n",
      "+------+-------+------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import SparkSession from pyspark.sql\n",
    "from pyspark.sql import SparkSession\n",
    "# Create my_spark\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "# load ratings data\n",
    "ratings = spark.read.csv(\"ml-latest-small/ratings.csv\", header=True, inferSchema=True)\n",
    "print(\"Number of ratings: %i\" % ratings.count())\n",
    "print(\"Sample of ratings:\")\n",
    "ratings.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['userId', 'movieId', 'rating', 'timestamp']\n"
     ]
    }
   ],
   "source": [
    "# Look at the column names\n",
    "print (ratings.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ratings dataframe is  98.30% empty.\n"
     ]
    }
   ],
   "source": [
    "# Count the total number of ratings in the dataset\n",
    "numerator = ratings.select(\"rating\").count()\n",
    "\n",
    "# Count the number of distinct users.\n",
    "num_users = ratings.select(\"userId\").distinct().count()\n",
    "\n",
    "# Count the number of distinct movies.\n",
    "num_movies = ratings.select(\"movieId\").distinct().count()\n",
    "\n",
    "# Set the denominator equal to the number of users multiplied by the number of movies\n",
    "denominator = num_users * num_movies\n",
    "\n",
    "# Divide the numerator by the denominator\n",
    "sparsity = (1.0 - (numerator *1.0)/denominator)*100\n",
    "print (\"The ratings dataframe is \", \"%.2f\" % sparsity + \"% empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The GroupBy and Filter Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|      1|   4.0|964982703|\n",
      "|     1|      3|   4.0|964981247|\n",
      "|     1|      6|   4.0|964982224|\n",
      "|     1|     47|   5.0|964983815|\n",
      "|     1|     50|   5.0|964982931|\n",
      "|     1|     70|   3.0|964982400|\n",
      "|     1|    101|   5.0|964980868|\n",
      "|     1|    110|   4.0|964982176|\n",
      "|     1|    151|   5.0|964984041|\n",
      "|     1|    157|   5.0|964984100|\n",
      "|     1|    163|   5.0|964983650|\n",
      "|     1|    216|   5.0|964981208|\n",
      "|     1|    223|   3.0|964980985|\n",
      "|     1|    231|   5.0|964981179|\n",
      "|     1|    235|   4.0|964980908|\n",
      "|     1|    260|   5.0|964981680|\n",
      "|     1|    296|   3.0|964982967|\n",
      "|     1|    316|   3.0|964982310|\n",
      "|     1|    333|   5.0|964981179|\n",
      "|     1|    349|   4.0|964982563|\n",
      "+------+-------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|      1|   4.0|964982703|\n",
      "|     1|      3|   4.0|964981247|\n",
      "|     1|      6|   4.0|964982224|\n",
      "|     1|     47|   5.0|964983815|\n",
      "|     1|     50|   5.0|964982931|\n",
      "|     1|     70|   3.0|964982400|\n",
      "|     1|    101|   5.0|964980868|\n",
      "|     1|    110|   4.0|964982176|\n",
      "|     1|    151|   5.0|964984041|\n",
      "|     1|    157|   5.0|964984100|\n",
      "|     1|    163|   5.0|964983650|\n",
      "|     1|    216|   5.0|964981208|\n",
      "|     1|    223|   3.0|964980985|\n",
      "|     1|    231|   5.0|964981179|\n",
      "|     1|    235|   4.0|964980908|\n",
      "|     1|    260|   5.0|964981680|\n",
      "|     1|    296|   3.0|964982967|\n",
      "|     1|    316|   3.0|964982310|\n",
      "|     1|    333|   5.0|964981179|\n",
      "|     1|    349|   4.0|964982563|\n",
      "+------+-------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------+-----+\n",
      "|userId|count|\n",
      "+------+-----+\n",
      "|   148|   48|\n",
      "|   463|   33|\n",
      "|   471|   28|\n",
      "|   496|   29|\n",
      "|   243|   36|\n",
      "|   392|   25|\n",
      "|   540|   42|\n",
      "|    31|   50|\n",
      "|   516|   26|\n",
      "|    85|   34|\n",
      "|   137|  141|\n",
      "|   251|   23|\n",
      "|   451|   34|\n",
      "|   580|  436|\n",
      "|    65|   34|\n",
      "|   458|   59|\n",
      "|    53|   20|\n",
      "|   255|   44|\n",
      "|   481|   31|\n",
      "|   588|   56|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the requisite packages\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# View the ratings dataset\n",
    "ratings.show()\n",
    "\n",
    "# Filter out all userIds greater than 100\n",
    "ratings.filter(col(\"userId\") < 100).show()\n",
    "\n",
    "# Group data by userId, count ratings\n",
    "ratings.groupBy(\"userId\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie with the fewest ratings: \n",
      "+----------+\n",
      "|min(count)|\n",
      "+----------+\n",
      "|         1|\n",
      "+----------+\n",
      "\n",
      "Avg num ratings per movie: \n",
      "+------------------+\n",
      "|        avg(count)|\n",
      "+------------------+\n",
      "|10.369806663924312|\n",
      "+------------------+\n",
      "\n",
      "User with the fewest ratings: \n",
      "+----------+\n",
      "|min(count)|\n",
      "+----------+\n",
      "|        20|\n",
      "+----------+\n",
      "\n",
      "Avg num ratings per user: \n",
      "+------------------+\n",
      "|        avg(count)|\n",
      "+------------------+\n",
      "|165.30491803278687|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import min,avg\n",
    "\n",
    "# Min num ratings for movies\n",
    "print(\"Movie with the fewest ratings: \")\n",
    "ratings.groupBy(\"movieId\").count().select(min(\"count\")).show()\n",
    "# Avg num ratings per movie\n",
    "print(\"Avg num ratings per movie: \")\n",
    "ratings.groupBy(\"movieId\").count().select(avg(\"count\")).show()\n",
    "\n",
    "# Min num ratings for user\n",
    "print(\"User with the fewest ratings: \")\n",
    "ratings.groupBy(\"userId\").count().select(min(\"count\")).show()\n",
    "\n",
    "# Avg num ratings per users\n",
    "print(\"Avg num ratings per user: \")\n",
    "ratings.groupBy(\"userId\").count().select(avg(\"count\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the .printSchema() method to see the datatypes of the ratings dataset.\n",
    "ratings.printSchema()\n",
    "\n",
    "# Tell Spark to convert the columns to the proper data types.\n",
    "ratings = ratings.select(ratings.userId.cast(\"integer\"), ratings.movieId.cast(\"integer\"), ratings.rating.cast(\"double\"))\n",
    "\n",
    "# Call .printSchema() again to confirm the columns are now in the correct format\n",
    "ratings.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create test/train splits and build your ALS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.recommendation.ALS"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import ParamGridBuilder,CrossValidator\n",
    "\n",
    "# Create test and train set\n",
    "(train, test) = ratings.randomSplit([0.80, 0.20], seed = 1234)\n",
    "\n",
    "# Create ALS model\n",
    "als = ALS(userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", nonnegative = True, implicitPrefs = False)\n",
    "\n",
    "# Confirm that a model called \"als\" was created\n",
    "type(als)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tune ALS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num models to be tested:  8\n"
     ]
    }
   ],
   "source": [
    "# Import the requisite items\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder,CrossValidator\n",
    "\n",
    "# Add hyperparameters and their respective values to param_grid\n",
    "param_grid= ParamGridBuilder() \n",
    "param_grid=param_grid.addGrid(als.rank, [50, 100])\n",
    "param_grid=param_grid.addGrid(als.maxIter, [10, 20]) \n",
    "param_grid=param_grid.addGrid(als.regParam, [.05, .1]) \n",
    "param_grid=param_grid.build()\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\") \n",
    "print (\"Num models to be tested: \", len(param_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build your cross validation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossValidator_793f8f6cd821\n"
     ]
    }
   ],
   "source": [
    "# Build cross validator\n",
    "cv = CrossValidator(estimator=als, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=5)\n",
    "\n",
    "# Confirm cv was built\n",
    "print (cv)\n",
    "\n",
    "#Fit cross validator to the 'train' dataset\n",
    "model = cv.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model and Best Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.ml.recommendation.ALSModel'>\n",
      "**Best Model**\n"
     ]
    }
   ],
   "source": [
    "#Extract best model from the cv model above\n",
    "best_model = model.bestModel\n",
    "\n",
    "# Print best_model\n",
    "print(type(best_model))\n",
    "\n",
    "# Complete the code below to extract the ALS model parameters\n",
    "print(\"**Best Model**\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rank: 50\n",
      "  MaxIter: 10\n",
      "  RegParam: 0.05\n"
     ]
    }
   ],
   "source": [
    "# Print \"Rank\"\n",
    "print(\"  Rank:\", best_model._java_obj.parent().getRank())\n",
    "# Print \"MaxIter\"\n",
    "print(\"  MaxIter:\", best_model._java_obj.parent().getMaxIter())\n",
    "\n",
    "# Print \"RegParam\"\n",
    "print(\"  RegParam:\", best_model._java_obj.parent().getRegParam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate predictions and calculate RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_predictions = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|   385|    471|   4.0| 3.0619082|\n",
      "|   462|    471|   2.5| 2.7239828|\n",
      "|   387|    471|   3.0|  2.855985|\n",
      "|   171|    471|   3.0| 5.0116787|\n",
      "|    32|    471|   3.0| 4.1348567|\n",
      "|   469|    471|   5.0| 3.4102752|\n",
      "|   357|    471|   3.5|  4.144864|\n",
      "|   191|    496|   5.0|       NaN|\n",
      "|   132|   1088|   4.0| 2.9508123|\n",
      "|   563|   1088|   4.0| 3.4017477|\n",
      "|   594|   1088|   4.5|  4.299285|\n",
      "|   307|   1088|   3.0| 2.2142334|\n",
      "|    51|   1088|   4.0| 3.8735592|\n",
      "|   221|   1088|   3.0| 2.9568038|\n",
      "|   414|   1088|   3.0| 2.9884179|\n",
      "|   200|   1088|   4.0| 3.7016778|\n",
      "|   104|   1088|   3.0| 3.8977597|\n",
      "|    19|   1238|   3.0| 2.8326402|\n",
      "|   156|   1238|   4.0|  3.548694|\n",
      "|   425|   1342|   3.5| 2.1621828|\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View the predictions \n",
    "test_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select the first set of columns\n",
    "selected1 = test_predictions.select(\"userId\",\"movieId\",\"rating\",\"prediction\")\n",
    "# Define first filter\n",
    "predictions = selected1.filter(test_predictions.prediction != 'NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9315846852540457\n"
     ]
    }
   ],
   "source": [
    "rmse = evaluator.evaluate(predictions)\n",
    "print('RMSE:', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 60's Ratings:\n",
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|    60|    318|   4.0|\n",
      "|    60|   6016|   4.0|\n",
      "|    60|    783|   4.0|\n",
      "|    60|   1203|   3.0|\n",
      "+------+-------+------+\n",
      "\n",
      "User 60s Recommendations:\n",
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|    60|    318|   4.0|  4.520606|\n",
      "|    60|   1203|   3.0|  4.465421|\n",
      "|    60|    783|   4.0| 3.0083368|\n",
      "|    60|   6016|   4.0|  4.255051|\n",
      "+------+-------+------+----------+\n",
      "\n",
      "User 63's Ratings:\n",
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|    63|    318|   5.0|\n",
      "|    63|   1220|   5.0|\n",
      "|    63|   1288|   5.0|\n",
      "|    63|    344|   5.0|\n",
      "|    63|   2716|   5.0|\n",
      "|    63|  33779|   5.0|\n",
      "|    63|  77455|   5.0|\n",
      "|    63|  89753|   5.0|\n",
      "|    63| 111781|   5.0|\n",
      "|    63| 115617|   5.0|\n",
      "|    63| 134853|   5.0|\n",
      "|    63|   2078|   5.0|\n",
      "|    63|     50|   5.0|\n",
      "|    63|    260|   5.0|\n",
      "|    63|   2858|   5.0|\n",
      "|    63|   1198|   5.0|\n",
      "|    63|  64285|   4.5|\n",
      "|    63|  73017|   4.0|\n",
      "|    63|   8464|   4.0|\n",
      "|    63|  74458|   4.0|\n",
      "+------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "User 63's Recommendations:\n",
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|    63|  48780|   3.5| 4.3684587|\n",
      "|    63|   3000|   3.5| 3.9696639|\n",
      "|    63|   7387|   2.0| 3.2488484|\n",
      "|    63|  89753|   5.0| 2.3860545|\n",
      "|    63| 106487|   0.5| 3.1208315|\n",
      "|    63|   1198|   5.0|   4.10084|\n",
      "|    63|   8464|   4.0|  3.014207|\n",
      "|    63|   2683|   3.0| 2.6435456|\n",
      "|    63|   8917|   4.0| 3.6455956|\n",
      "|    63|    924|   3.5| 3.8659365|\n",
      "|    63|    111|   3.0| 3.5730665|\n",
      "|    63|  96079|   3.5| 3.8949895|\n",
      "|    63|  67997|   4.0| 3.1021242|\n",
      "|    63|   1288|   5.0| 3.4978876|\n",
      "|    63|   3421|   2.5| 3.4934256|\n",
      "|    63|   6365|   2.0|   2.58532|\n",
      "|    63|   1682|   3.5| 3.5466363|\n",
      "|    63|    500|   3.0| 3.0085387|\n",
      "|    63|  91630|   4.0| 2.6192157|\n",
      "|    63|  74458|   4.0| 4.2565727|\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look at user 60's ratings\n",
    "print (\"User 60's Ratings:\")\n",
    "test.filter(col(\"userId\") == 60).sort(\"rating\",ascending = False).show()\n",
    "\n",
    "# Look at the movies recommended to user 60\n",
    "print (\"User 60s Recommendations:\")\n",
    "test_predictions.filter(col(\"userId\") == 60).show()\n",
    "\n",
    "# Look at user 63's ratings\n",
    "print (\"User 63's Ratings:\")\n",
    "test.filter(col(\"userId\") == 63).sort(\"rating\", ascending = False).show()\n",
    "\n",
    "# Look at the movies recommended to user 63\n",
    "print (\"User 63's Recommendations:\")\n",
    "test_predictions.filter(col(\"userId\") == 63).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load raw data from movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw movie data:\n",
      "+-------+----------------------------------+-------------------------------------------+\n",
      "|movieId|title                             |genres                                     |\n",
      "+-------+----------------------------------+-------------------------------------------+\n",
      "|1      |Toy Story (1995)                  |Adventure|Animation|Children|Comedy|Fantasy|\n",
      "|2      |Jumanji (1995)                    |Adventure|Children|Fantasy                 |\n",
      "|3      |Grumpier Old Men (1995)           |Comedy|Romance                             |\n",
      "|4      |Waiting to Exhale (1995)          |Comedy|Drama|Romance                       |\n",
      "|5      |Father of the Bride Part II (1995)|Comedy                                     |\n",
      "+-------+----------------------------------+-------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movie_info = spark.read.csv(\"ml-latest-small/movies.csv\", header=True, inferSchema=True)\n",
    "print(\"Raw movie data:\")\n",
    "movie_info.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|userId|movieId|\n",
      "+------+-------+\n",
      "|   200|     34|\n",
      "|   200|    435|\n",
      "|   200|    480|\n",
      "|   200|    586|\n",
      "|   200|    852|\n",
      "|   200|   1028|\n",
      "|   200|   1036|\n",
      "|   200|   1088|\n",
      "|   200|   1198|\n",
      "|   200|   1250|\n",
      "|   200|   1391|\n",
      "|   200|   1500|\n",
      "|   200|   1517|\n",
      "|   200|   1569|\n",
      "|   200|   2012|\n",
      "|   200|   2248|\n",
      "|   200|   2502|\n",
      "|   200|   2581|\n",
      "|   200|   2991|\n",
      "|   200|   3253|\n",
      "+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "this_user = test.filter(test['userId'] == 200).select('userId', 'movieId')\n",
    "this_user.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+----------+\n",
      "|userId|movieId|prediction|\n",
      "+------+-------+----------+\n",
      "|   200|   1088| 3.7016778|\n",
      "|   200|   4161| 3.7567112|\n",
      "|   200|   6934| 3.2413628|\n",
      "|   200|   6378| 3.6304917|\n",
      "|   200|  58559| 4.3657455|\n",
      "|   200|     34| 3.0511289|\n",
      "|   200|   1198|  4.590148|\n",
      "|   200|   1500| 3.4712083|\n",
      "|   200|  30793|  4.346811|\n",
      "|   200|   3481| 3.6183228|\n",
      "|   200|   2502|  4.489507|\n",
      "|   200|   6503| 2.5988638|\n",
      "|   200|  53996| 3.4248185|\n",
      "|   200|   4246| 3.4882336|\n",
      "|   200|   7361| 3.9417608|\n",
      "|   200|    435|  2.510918|\n",
      "|   200|   1391| 3.1258621|\n",
      "|   200|   4979| 3.6850567|\n",
      "|   200|    852| 2.7579849|\n",
      "|   200|  56949| 3.7036724|\n",
      "+------+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recommendation_this_user = model.transform(this_user)\n",
    "recommendation_this_user.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+----------+--------------------+--------------------+\n",
      "|movieId|userId|prediction|               title|              genres|\n",
      "+-------+------+----------+--------------------+--------------------+\n",
      "|   2991|   200| 4.7491813|Live and Let Die ...|Action|Adventure|...|\n",
      "|   3253|   200| 4.6182733|Wayne's World (1992)|              Comedy|\n",
      "|   1198|   200|  4.590148|Raiders of the Lo...|    Action|Adventure|\n",
      "|   1250|   200|  4.532661|Bridge on the Riv...| Adventure|Drama|War|\n",
      "|   5989|   200|  4.521723|Catch Me If You C...|         Crime|Drama|\n",
      "|   2502|   200|  4.489507| Office Space (1999)|        Comedy|Crime|\n",
      "|   4816|   200| 4.4075074|    Zoolander (2001)|              Comedy|\n",
      "|   4886|   200|  4.383157|Monsters, Inc. (2...|Adventure|Animati...|\n",
      "|  58559|   200| 4.3657455|Dark Knight, The ...|Action|Crime|Dram...|\n",
      "|  54503|   200| 4.3490386|     Superbad (2007)|              Comedy|\n",
      "|  30793|   200|  4.346811|Charlie and the C...|Adventure|Childre...|\n",
      "|  48738|   200| 4.3264456|Last King of Scot...|      Drama|Thriller|\n",
      "|  46578|   200|  4.277913|Little Miss Sunsh...|Adventure|Comedy|...|\n",
      "|   3809|   200|  4.262687|What About Bob? (...|              Comedy|\n",
      "|   4226|   200|  4.228711|      Memento (2000)|    Mystery|Thriller|\n",
      "|   2248|   200| 4.1835155|Say Anything... (...|Comedy|Drama|Romance|\n",
      "|   8874|   200|  4.170795|Shaun of the Dead...|       Comedy|Horror|\n",
      "|   3578|   200| 4.1625147|    Gladiator (2000)|Action|Adventure|...|\n",
      "|   1028|   200| 4.1057243| Mary Poppins (1964)|Children|Comedy|F...|\n",
      "|   5481|   200|  4.104925|Austin Powers in ...|              Comedy|\n",
      "+-------+------+----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Join the DataFrames\n",
    "recommendation_this_user_movies = recommendation_this_user.join(raw_movies,on='movieId',how=\"leftouter\")\n",
    "\n",
    "# Examine the data again\n",
    "print(recommendation_this_user_movies.orderBy('prediction', ascending=False).filter(recommendation_this_user_movies.prediction != 'NaN').show())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
